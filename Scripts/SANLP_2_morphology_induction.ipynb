{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK3D6HTE-Ai3"
      },
      "source": [
        "# Linguistica - Unsupervised Learning of Morphology\n",
        "\n",
        "https://linguistica-uchicago.github.io/lxa5/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca_R7jtl-M6d"
      },
      "source": [
        "installing linguistica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bGgbCTkKGGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c12fae69-7a81-48d7-e762-d911cd836ac2"
      },
      "source": [
        "!pip install linguistica\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting linguistica\n",
            "  Downloading linguistica-5.2.1-py2.py3-none-any.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from linguistica) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.10/dist-packages (from linguistica) (1.23.5)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from linguistica) (1.11.3)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from linguistica) (3.1)\n",
            "Installing collected packages: linguistica\n",
            "Successfully installed linguistica-5.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHpav91h-YW6"
      },
      "source": [
        "The corpus file is in the google drive.\n",
        "\n",
        "Mounting the google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7GyVoWmJXBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6bf0b1-feaf-48ac-954d-cbeedef9df93"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVqe29r5_FJ6"
      },
      "source": [
        "filepath = \"/content/drive/My Drive/UniKonstanz/South Asian NLP/data/\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7X6pryV_G8X"
      },
      "source": [
        "Reading the corpus.\n",
        "\n",
        "It is better that the corpus is pre-pocessed as the urdu/arabic punctuation marks remain attached with the words in the current processing.\n",
        "(Note: It does not matter for the current file as that is in Roman script.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmoQfiw2JXBp"
      },
      "source": [
        "import linguistica as lxa\n",
        "\n",
        "lxa_ur = lxa.read_corpus(filepath+\"roman_urdu_news.txt\", max_affix_length=5, min_stem_length = 3, min_sig_count=3, max_word_tokens=15000)\n",
        "lxa_ta = lxa.read_corpus(filepath+\"Tamil_Roman_Text.txt\", max_affix_length=5, min_stem_length = 3, min_sig_count=3, max_word_tokens=15000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hFexfbKM3LX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TzUm0ieW3NTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tamil Roman Text**"
      ],
      "metadata": {
        "id": "l28GMAA93KRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lxa_ta.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U3S8BCuONW6",
        "outputId": "80694d2d-ea22-43b0-b01e-620b44c95929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_word_tokens': 15000,\n",
              " 'min_stem_length': 3,\n",
              " 'max_affix_length': 5,\n",
              " 'min_sig_count': 3,\n",
              " 'n_neighbors': 9,\n",
              " 'n_eigenvectors': 11,\n",
              " 'min_context_count': 3,\n",
              " 'max_word_types': 1000,\n",
              " 'suffixing': 1,\n",
              " 'keep_case': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao1g6uwNPL4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58d460f2-310d-4bc1-93ff-33668e59094d"
      },
      "source": [
        "lxa_ta.affixes()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NULL',\n",
              " 'a',\n",
              " 'aa',\n",
              " 'aaa',\n",
              " 'ae',\n",
              " 'aga',\n",
              " 'ala',\n",
              " 'am',\n",
              " 'an',\n",
              " 'ana',\n",
              " 'da',\n",
              " 'di',\n",
              " 'e',\n",
              " 'ed',\n",
              " 'en',\n",
              " 'ga',\n",
              " 'h',\n",
              " 'ha',\n",
              " 'hu',\n",
              " 'i',\n",
              " 'ing',\n",
              " 'k',\n",
              " 'ka',\n",
              " 'ku',\n",
              " 'la',\n",
              " 'luku',\n",
              " 'lum',\n",
              " 'ly',\n",
              " 'm',\n",
              " 'n',\n",
              " 'na',\n",
              " 'nga',\n",
              " 'ngala',\n",
              " 'nu',\n",
              " 'num',\n",
              " 'o',\n",
              " 'r',\n",
              " 's',\n",
              " 'ss',\n",
              " 'than',\n",
              " 'thu',\n",
              " 'u',\n",
              " 'uku',\n",
              " 'um',\n",
              " 'va',\n",
              " 'w',\n",
              " 'y',\n",
              " 'ya',\n",
              " 'ye',\n",
              " 'yum'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Urdu Roman Text**"
      ],
      "metadata": {
        "id": "1F1lF_vc3bTO"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX9YmCsW_kKQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0dfac7e-76c3-45bc-f104-2d114d7eee69"
      },
      "source": [
        "lxa_ta.signatures()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('NULL', 'a'),\n",
              " ('NULL', 'aa'),\n",
              " ('NULL', 'aaa'),\n",
              " ('NULL', 'am'),\n",
              " ('NULL', 'da'),\n",
              " ('NULL', 'di'),\n",
              " ('NULL', 'e'),\n",
              " ('NULL', 'ed'),\n",
              " ('NULL', 'ga'),\n",
              " ('NULL', 'h'),\n",
              " ('NULL', 'ha'),\n",
              " ('NULL', 'hu'),\n",
              " ('NULL', 'i'),\n",
              " ('NULL', 'ing'),\n",
              " ('NULL', 'k'),\n",
              " ('NULL', 'ku'),\n",
              " ('NULL', 'la'),\n",
              " ('NULL', 'luku'),\n",
              " ('NULL', 'lum'),\n",
              " ('NULL', 'ly'),\n",
              " ('NULL', 'm'),\n",
              " ('NULL', 'm', 'nu'),\n",
              " ('NULL', 'n'),\n",
              " ('NULL', 'na'),\n",
              " ('NULL', 'nga'),\n",
              " ('NULL', 'nu'),\n",
              " ('NULL', 'num'),\n",
              " ('NULL', 'r'),\n",
              " ('NULL', 's'),\n",
              " ('NULL', 'ss'),\n",
              " ('NULL', 'than'),\n",
              " ('NULL', 'thu'),\n",
              " ('NULL', 'u'),\n",
              " ('NULL', 'uku'),\n",
              " ('NULL', 'va'),\n",
              " ('NULL', 'w'),\n",
              " ('NULL', 'y'),\n",
              " ('NULL', 'ya'),\n",
              " ('NULL', 'ye'),\n",
              " ('NULL', 'yum'),\n",
              " ('a', 'e'),\n",
              " ('a', 'i'),\n",
              " ('a', 'o'),\n",
              " ('a', 'u'),\n",
              " ('ae', 'e'),\n",
              " ('aga', 'u'),\n",
              " ('ala', 'um'),\n",
              " ('am', 'm'),\n",
              " ('an', 'en'),\n",
              " ('an', 'n'),\n",
              " ('ana', 'na'),\n",
              " ('e', 'ing'),\n",
              " ('e', 'um'),\n",
              " ('ga', 'ka'),\n",
              " ('ga', 'nga'),\n",
              " ('ga', 'nga', 'ngala'),\n",
              " ('i', 'u'),\n",
              " ('i', 'y'),\n",
              " ('ku', 'u'),\n",
              " ('m', 'n'),\n",
              " ('n', 'r')}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lxa_ta.signatures_to_stems()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YTN09YOTtN0",
        "outputId": "5910f774-6d7b-4b72-9329-c5a980592956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('a', 'e'): {'#thal',\n",
              "  'agal',\n",
              "  'dat',\n",
              "  'eruking',\n",
              "  'kitt',\n",
              "  'kollam',\n",
              "  'nadik',\n",
              "  'niray',\n",
              "  'soldravang',\n",
              "  'vay'},\n",
              " ('NULL', 'a'): {'*tha',\n",
              "  'ahaaa',\n",
              "  'apdiye',\n",
              "  'athigam',\n",
              "  'dekh',\n",
              "  'done',\n",
              "  'inka',\n",
              "  'innoruthar',\n",
              "  'inoruthar',\n",
              "  'irukum',\n",
              "  'irundha',\n",
              "  'ithan',\n",
              "  'kaaga',\n",
              "  'kamal',\n",
              "  'kandipa',\n",
              "  'kollaam',\n",
              "  'lam',\n",
              "  'laye',\n",
              "  'leval',\n",
              "  'likes',\n",
              "  'maranam',\n",
              "  'neram',\n",
              "  'oruthar',\n",
              "  'parunga',\n",
              "  'ready',\n",
              "  'record',\n",
              "  'sanda',\n",
              "  'sapda',\n",
              "  'sethupathy',\n",
              "  'shradha',\n",
              "  'solluravanga',\n",
              "  'super',\n",
              "  'terika',\n",
              "  'thalaivaaaaaaaaaaa',\n",
              "  'thalavar',\n",
              "  'theriyath',\n",
              "  'varusam',\n",
              "  'vegam',\n",
              "  'vijay',\n",
              "  'villain',\n",
              "  'yan',\n",
              "  'yennada'},\n",
              " ('NULL', 'k'): {'102', '400', '700', 'karthi'},\n",
              " ('NULL', 'aaa'): {'anna', 'daaaaaa', 'semmaaaa', 'thalaaaaaaaaa'},\n",
              " ('NULL', 'luku'): {'enga', 'pathavanga', 'yenga'},\n",
              " ('NULL', 'aa'): {'aaaa',\n",
              "  'nna',\n",
              "  'paaaaaaa',\n",
              "  'pakkka',\n",
              "  'pothum',\n",
              "  'semmma',\n",
              "  'verithanam'},\n",
              " ('NULL', 'la'): {'chennai',\n",
              "  'cinema',\n",
              "  'gandu',\n",
              "  'irukinga',\n",
              "  'kaandu',\n",
              "  'kandu',\n",
              "  'parvai',\n",
              "  'pasanga',\n",
              "  'poga',\n",
              "  'screen',\n",
              "  'solravanga',\n",
              "  'thanda',\n",
              "  'trending',\n",
              "  'ungala',\n",
              "  'vanthavanga'},\n",
              " ('NULL', 'num'): {'eduka', 'paakka', 'saaga', 'saga', 'thara', 'vaanga'},\n",
              " ('a', 'i'): {'ood', 'pal', 'poy', 'pudich', 'rah', 'thadav', 'vad'},\n",
              " ('ala', 'um'): {'pudik', 'puriy', 'theriy'},\n",
              " ('NULL', 'i'): {'aah',\n",
              "  'epd',\n",
              "  'kaidhi',\n",
              "  'kalyan',\n",
              "  'move',\n",
              "  'nahi',\n",
              "  'paarva',\n",
              "  'padipa',\n",
              "  'petta',\n",
              "  'picha',\n",
              "  'puriyala',\n",
              "  'rajan',\n",
              "  'rajini',\n",
              "  'vela',\n",
              "  'vetta'},\n",
              " ('a', 'u'): {'aal',\n",
              "  'ennad',\n",
              "  'ennan',\n",
              "  'gethth',\n",
              "  'irrundh',\n",
              "  'katt',\n",
              "  'mudiv',\n",
              "  'mutt',\n",
              "  'padip',\n",
              "  'padipp',\n",
              "  'paduth',\n",
              "  'parth',\n",
              "  'sang',\n",
              "  'sapad'},\n",
              " ('NULL', 'lum'): {'ana', 'eruntha', 'naanga', 'paatha'},\n",
              " ('NULL', 'ing'): {'act', 'even', 'expect', 'feel', 'hang', 'watch', 'what'},\n",
              " ('NULL', 's'): {'actor',\n",
              "  'award',\n",
              "  'bot',\n",
              "  'cartoon',\n",
              "  'cell',\n",
              "  'comment',\n",
              "  'day',\n",
              "  'director',\n",
              "  'hit',\n",
              "  'hour',\n",
              "  'let',\n",
              "  'line',\n",
              "  'love',\n",
              "  'maas',\n",
              "  'massssssss',\n",
              "  'million',\n",
              "  'moment',\n",
              "  'movie',\n",
              "  'new',\n",
              "  'option',\n",
              "  'phone',\n",
              "  'scene',\n",
              "  'sec',\n",
              "  'shot',\n",
              "  'show',\n",
              "  'song',\n",
              "  'tamilan',\n",
              "  'veriyan',\n",
              "  'vikram'},\n",
              " ('NULL', 'n'): {'dam',\n",
              "  'dhaa',\n",
              "  'konda',\n",
              "  'manitha',\n",
              "  'muga',\n",
              "  'muruga',\n",
              "  'poda',\n",
              "  'rasika',\n",
              "  'sama',\n",
              "  'selva',\n",
              "  'tamila',\n",
              "  'thaaa',\n",
              "  'thlaiva',\n",
              "  'vittiduve'},\n",
              " ('NULL', 'ya'): {'ilama', 'mathiri', 'pala', 'suri', 'varla'},\n",
              " ('i', 'u'): {'kuth', 'vach', 'vech'},\n",
              " ('NULL', 'am'): {'adikk', 'all', 'herova', 'sath'},\n",
              " ('NULL', 'nu'): {'agala', 'pakanum', 'vechi'},\n",
              " ('NULL', 'm', 'nu'): {'eruku', 'irukku', 'porom'},\n",
              " ('NULL', 'h'): {'ajit', 'kant', 'pahh', 'rajnikant', 'ranjit'},\n",
              " ('NULL', 'ku'): {'ajith',\n",
              "  'alavu',\n",
              "  'announcement',\n",
              "  'diwali',\n",
              "  'edhu',\n",
              "  'hours',\n",
              "  'manasu',\n",
              "  'nalai',\n",
              "  'superstar',\n",
              "  'una',\n",
              "  'vaati'},\n",
              " ('NULL', 'ga'): {'irukken', 'jay', 'maatan', 'panravan', 'pottavan'},\n",
              " ('NULL', 'm'): {'alagu',\n",
              "  'avangala',\n",
              "  'ela',\n",
              "  'endru',\n",
              "  'innu',\n",
              "  'inu',\n",
              "  'katala',\n",
              "  'mairu',\n",
              "  'nanu',\n",
              "  'onnu',\n",
              "  'pannala',\n",
              "  'pothu',\n",
              "  'rendu',\n",
              "  'tee',\n",
              "  'thanga',\n",
              "  'vanthalu',\n",
              "  'vanthathu',\n",
              "  'verithana',\n",
              "  'yaaru',\n",
              "  'yaruku',\n",
              "  'yellaa'},\n",
              " ('NULL', 'ly'): {'amazing', 'dai', 'high'},\n",
              " ('NULL', 'ha'): {'and', 'hahaha', 'wat'},\n",
              " ('NULL', 'di'): {'apa', 'eppa', 'ippa'},\n",
              " ('NULL', 'ye'): {'apadi', 'maari', 'madhiri', 'munnadi', 'paakama', 'pogala'},\n",
              " ('NULL', 'na'): {'atha', 'etha', 'getha', 'panringa', 'unmaiya'},\n",
              " ('ae', 'e'): {'apdiy', 'eduthukav', 'polay'},\n",
              " ('NULL', 'da'): {'appa',\n",
              "  'epdi',\n",
              "  'ethukku',\n",
              "  'evano',\n",
              "  'gethu',\n",
              "  'pooga',\n",
              "  'solla',\n",
              "  'vidunga'},\n",
              " ('a', 'o'): {'app', 'ayy', 'poduving'},\n",
              " ('NULL', 'va'): {'appadiye', 'hero', 'summa'},\n",
              " ('am', 'm'): {'apr', 'ethella', 'visvas'},\n",
              " ('NULL', 'than'): {'innoru', 'kani', 'oru', 'siripu'},\n",
              " ('ku', 'u'): {'athuk', 'enak', 'ethuk', 'padathuk', 'pongaluk', 'ungaluk'},\n",
              " ('NULL', 'r'): {'dupe',\n",
              "  'hai',\n",
              "  'make',\n",
              "  'sanga',\n",
              "  'sir',\n",
              "  'sirr',\n",
              "  'thailaiva',\n",
              "  'you'},\n",
              " ('n', 'r'): {'eve', 'nadiga', 'rasiga'},\n",
              " ('NULL', 'u'): {'irukar',\n",
              "  'levelu',\n",
              "  'mudiyathu',\n",
              "  'seen',\n",
              "  'subburaj',\n",
              "  'takkar'},\n",
              " ('NULL', 'ed'): {'book', 'break', 'reach'},\n",
              " ('NULL', 'uku'): {'manusan', 'oruthan', 'rasikan'},\n",
              " ('an', 'n'): {'chiya', 'panrav', 'sakthima'},\n",
              " ('e', 'ing'): {'com', 'gam', 'shar', 'tim'},\n",
              " ('m', 'n'): {'confir', 'mattu', 'pava'},\n",
              " ('NULL', 'y'): {'cop',\n",
              "  'eppavume',\n",
              "  'ever',\n",
              "  'mavane',\n",
              "  'pande',\n",
              "  'sex',\n",
              "  'vayase'},\n",
              " ('NULL', 'w'): {'wow', 'woww', 'wowwwww'},\n",
              " ('NULL', 'e'): {'evanum',\n",
              "  'laya',\n",
              "  'mariya',\n",
              "  'not',\n",
              "  'ode',\n",
              "  'ora',\n",
              "  'padama',\n",
              "  'pengal',\n",
              "  'pleas',\n",
              "  'theivam'},\n",
              " ('aga', 'u'): {'engaluk', 'kaatrathuk', 'katrathuk'},\n",
              " ('e', 'um'): {'kagav', 'pathal', 'scen', 'styl'},\n",
              " ('NULL', 'ss'): {'kolama', 'maranama', 'pre'},\n",
              " ('NULL', 'hu'): {'meet', 'mudiyad', 'put', 'set'},\n",
              " ('ga', 'ka'): {'katurathuka', 'neen', 'panun', 'vidun'},\n",
              " ('NULL', 'nga'): {'kathuko', 'odiru', 'paaru', 'pathi', 'thooku', 'vai'},\n",
              " ('NULL', 'thu'): {'kooda',\n",
              "  'kuda',\n",
              "  'nadaka',\n",
              "  'nadakka',\n",
              "  'podra',\n",
              "  'poran',\n",
              "  'sonna'},\n",
              " ('an', 'en'): {'karthikey', 'sivakarthikey', 'vidamat'},\n",
              " ('ga', 'nga', 'ngala'): {'iruki', 'pasa', 'solrava', 'vanthava'},\n",
              " ('ga', 'nga'): {'podathi', 'porava', 'pottava'},\n",
              " ('NULL', 'yum'): {'kaithi', 'thalaivara', 'vayasula'},\n",
              " ('i', 'y'): {'kutt', 'saam', 'thalapath'},\n",
              " ('ana', 'na'): {'sirappa', 'tarama', 'tharama'}}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm8UyoP0_mLO"
      },
      "source": [
        "The properties for the morphology learning. Some values are set above. Others have the default values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBVwkOlyQGoc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "070e7d5b-0fe6-4afa-892c-ab05f9a9c496"
      },
      "source": [
        "lxa_ur.parameters()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_word_tokens': 15000,\n",
              " 'min_stem_length': 3,\n",
              " 'max_affix_length': 5,\n",
              " 'min_sig_count': 3,\n",
              " 'n_neighbors': 9,\n",
              " 'n_eigenvectors': 11,\n",
              " 'min_context_count': 3,\n",
              " 'max_word_types': 1000,\n",
              " 'suffixing': 1,\n",
              " 'keep_case': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeqtd1dB_0_H"
      },
      "source": [
        "Listing all the affixes found."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY6LjXi5P_kl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f273fac-e835-4342-d7fe-af8083988e5e"
      },
      "source": [
        "lxa_ur.affixes()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'00>',\n",
              " '01>',\n",
              " '02>',\n",
              " '03>',\n",
              " '04>',\n",
              " '05>',\n",
              " '06>',\n",
              " '07>',\n",
              " '08>',\n",
              " '09>',\n",
              " '0>',\n",
              " '10>',\n",
              " '11>',\n",
              " '12>',\n",
              " '13>',\n",
              " '14>',\n",
              " '15>',\n",
              " '16>',\n",
              " '17>',\n",
              " '18>',\n",
              " '19>',\n",
              " '1>',\n",
              " '20>',\n",
              " '21>',\n",
              " '22>',\n",
              " '23>',\n",
              " '24>',\n",
              " '25>',\n",
              " '26>',\n",
              " '27>',\n",
              " '28>',\n",
              " '29>',\n",
              " '2>',\n",
              " '30>',\n",
              " '31>',\n",
              " '32>',\n",
              " '33>',\n",
              " '34>',\n",
              " '35>',\n",
              " '36>',\n",
              " '37>',\n",
              " '38>',\n",
              " '39>',\n",
              " '3>',\n",
              " '40>',\n",
              " '41>',\n",
              " '42>',\n",
              " '43>',\n",
              " '44>',\n",
              " '45>',\n",
              " '46>',\n",
              " '47>',\n",
              " '48>',\n",
              " '49>',\n",
              " '4>',\n",
              " '50>',\n",
              " '51>',\n",
              " '52>',\n",
              " '53>',\n",
              " '54>',\n",
              " '55>',\n",
              " '56>',\n",
              " '57>',\n",
              " '58>',\n",
              " '59>',\n",
              " '5>',\n",
              " '60>',\n",
              " '61>',\n",
              " '62>',\n",
              " '63>',\n",
              " '64>',\n",
              " '65>',\n",
              " '66>',\n",
              " '67>',\n",
              " '68>',\n",
              " '69>',\n",
              " '6>',\n",
              " '70>',\n",
              " '71>',\n",
              " '72>',\n",
              " '73>',\n",
              " '74>',\n",
              " '75>',\n",
              " '76>',\n",
              " '77>',\n",
              " '78>',\n",
              " '79>',\n",
              " '7>',\n",
              " '80>',\n",
              " '81>',\n",
              " '82>',\n",
              " '83>',\n",
              " '84>',\n",
              " '85>',\n",
              " '86>',\n",
              " '87>',\n",
              " '88>',\n",
              " '89>',\n",
              " '8>',\n",
              " '90>',\n",
              " '91>',\n",
              " '92>',\n",
              " '93>',\n",
              " '94>',\n",
              " '95>',\n",
              " '96>',\n",
              " '97>',\n",
              " '98>',\n",
              " '99>',\n",
              " '9>',\n",
              " '>',\n",
              " 'NULL',\n",
              " 'a',\n",
              " 'at',\n",
              " 'atī',\n",
              " 'aṉ',\n",
              " 'e',\n",
              " 'h',\n",
              " 'iī',\n",
              " 'l',\n",
              " 'ne',\n",
              " 'ng',\n",
              " 'rz',\n",
              " 's',\n",
              " 't',\n",
              " 'uṉ',\n",
              " 'z',\n",
              " 'ī',\n",
              " 'ئی',\n",
              " 'ا',\n",
              " 'ات',\n",
              " 'اتی',\n",
              " 'اں',\n",
              " 'ت',\n",
              " 'رز',\n",
              " 'ز',\n",
              " 'س',\n",
              " 'ل',\n",
              " 'نگ',\n",
              " 'نے',\n",
              " 'وں',\n",
              " 'ں',\n",
              " 'ہ',\n",
              " 'ی',\n",
              " 'ے',\n",
              " 'ṉ'}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5dvqbYx_7Va"
      },
      "source": [
        "Listing all the signatures. Signatures are set of affixes that are attached with a wordset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaPzf3a-PsP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988867af-ecb7-4a1b-a84c-5510bead1c28"
      },
      "source": [
        "lxa_ur.signatures()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('00>',\n",
              "  '01>',\n",
              "  '02>',\n",
              "  '03>',\n",
              "  '04>',\n",
              "  '05>',\n",
              "  '06>',\n",
              "  '07>',\n",
              "  '08>',\n",
              "  '09>',\n",
              "  '0>',\n",
              "  '10>',\n",
              "  '11>',\n",
              "  '12>',\n",
              "  '13>',\n",
              "  '14>',\n",
              "  '15>',\n",
              "  '16>',\n",
              "  '17>',\n",
              "  '18>',\n",
              "  '19>',\n",
              "  '1>',\n",
              "  '20>',\n",
              "  '21>',\n",
              "  '22>',\n",
              "  '23>',\n",
              "  '24>',\n",
              "  '25>',\n",
              "  '26>',\n",
              "  '27>',\n",
              "  '28>',\n",
              "  '29>',\n",
              "  '2>',\n",
              "  '30>',\n",
              "  '31>',\n",
              "  '32>',\n",
              "  '33>',\n",
              "  '34>',\n",
              "  '35>',\n",
              "  '36>',\n",
              "  '37>',\n",
              "  '38>',\n",
              "  '39>',\n",
              "  '3>',\n",
              "  '40>',\n",
              "  '41>',\n",
              "  '42>',\n",
              "  '43>',\n",
              "  '44>',\n",
              "  '45>',\n",
              "  '46>',\n",
              "  '47>',\n",
              "  '48>',\n",
              "  '49>',\n",
              "  '4>',\n",
              "  '50>',\n",
              "  '51>',\n",
              "  '52>',\n",
              "  '53>',\n",
              "  '54>',\n",
              "  '55>',\n",
              "  '56>',\n",
              "  '57>',\n",
              "  '58>',\n",
              "  '59>',\n",
              "  '5>',\n",
              "  '60>',\n",
              "  '61>',\n",
              "  '62>',\n",
              "  '63>',\n",
              "  '64>',\n",
              "  '65>',\n",
              "  '66>',\n",
              "  '67>',\n",
              "  '68>',\n",
              "  '69>',\n",
              "  '6>',\n",
              "  '70>',\n",
              "  '71>',\n",
              "  '72>',\n",
              "  '73>',\n",
              "  '74>',\n",
              "  '75>',\n",
              "  '76>',\n",
              "  '77>',\n",
              "  '78>',\n",
              "  '79>',\n",
              "  '7>',\n",
              "  '80>',\n",
              "  '81>',\n",
              "  '82>',\n",
              "  '83>',\n",
              "  '84>',\n",
              "  '85>',\n",
              "  '86>',\n",
              "  '87>',\n",
              "  '88>',\n",
              "  '89>',\n",
              "  '8>',\n",
              "  '90>',\n",
              "  '91>',\n",
              "  '92>',\n",
              "  '93>',\n",
              "  '94>',\n",
              "  '95>',\n",
              "  '96>',\n",
              "  '97>',\n",
              "  '98>',\n",
              "  '99>',\n",
              "  '9>',\n",
              "  '>'),\n",
              " ('0>', '1>', '2>', '3>', '4>', '5>', '6>', '7>', '8>', '9>', '>'),\n",
              " ('NULL', 'at'),\n",
              " ('NULL', 'atī'),\n",
              " ('NULL', 'aṉ'),\n",
              " ('NULL', 'e'),\n",
              " ('NULL', 'h'),\n",
              " ('NULL', 'iī'),\n",
              " ('NULL', 'l'),\n",
              " ('NULL', 'ne'),\n",
              " ('NULL', 'ng'),\n",
              " ('NULL', 'rz'),\n",
              " ('NULL', 's'),\n",
              " ('NULL', 't'),\n",
              " ('NULL', 'uṉ'),\n",
              " ('NULL', 'uṉ', 'ī'),\n",
              " ('NULL', 'z'),\n",
              " ('NULL', 'ī'),\n",
              " ('NULL', 'ئی'),\n",
              " ('NULL', 'ات'),\n",
              " ('NULL', 'اتی'),\n",
              " ('NULL', 'اں'),\n",
              " ('NULL', 'ت'),\n",
              " ('NULL', 'رز'),\n",
              " ('NULL', 'ز'),\n",
              " ('NULL', 'س'),\n",
              " ('NULL', 'ل'),\n",
              " ('NULL', 'نگ'),\n",
              " ('NULL', 'نے'),\n",
              " ('NULL', 'وں'),\n",
              " ('NULL', 'وں', 'ی'),\n",
              " ('NULL', 'ں'),\n",
              " ('NULL', 'ہ'),\n",
              " ('NULL', 'ی'),\n",
              " ('NULL', 'ے'),\n",
              " ('NULL', 'ṉ'),\n",
              " ('a', 'e'),\n",
              " ('a', 'ī'),\n",
              " ('e', 'h'),\n",
              " ('e', 'h', 'uṉ'),\n",
              " ('e', 'ī'),\n",
              " ('t', 'ī'),\n",
              " ('uṉ', 'ī'),\n",
              " ('ا', 'ی'),\n",
              " ('ا', 'ے'),\n",
              " ('ت', 'ی'),\n",
              " ('وں', 'ہ', 'ے'),\n",
              " ('وں', 'ی'),\n",
              " ('ہ', 'ے'),\n",
              " ('ی', 'ے')}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAt-BpDBAJNP"
      },
      "source": [
        "The signatures with the stems attached with the signature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ae2-4HaJXBs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69f3a7f9-a172-4894-de15-821c4e12cd21"
      },
      "source": [
        "lxa_ur.signatures_to_stems()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('0>', '1>', '2>', '3>', '4>', '5>', '6>', '7>', '8>', '9>', '>'): {'<r10',\n",
              "  '<r11',\n",
              "  '<r12',\n",
              "  '<r13',\n",
              "  '<r14',\n",
              "  '<r15',\n",
              "  '<r16',\n",
              "  '<r17',\n",
              "  '<r18',\n",
              "  '<r19',\n",
              "  '<r20',\n",
              "  '<r21',\n",
              "  '<r22',\n",
              "  '<r23',\n",
              "  '<r24',\n",
              "  '<r25',\n",
              "  '<r26',\n",
              "  '<r27',\n",
              "  '<r28',\n",
              "  '<r29',\n",
              "  '<r30',\n",
              "  '<r31',\n",
              "  '<r32',\n",
              "  '<r33',\n",
              "  '<r34',\n",
              "  '<r35',\n",
              "  '<r36',\n",
              "  '<r37',\n",
              "  '<r38',\n",
              "  '<r39',\n",
              "  '<r40',\n",
              "  '<r41',\n",
              "  '<r42',\n",
              "  '<r43',\n",
              "  '<r44',\n",
              "  '<r45',\n",
              "  '<r46',\n",
              "  '<r47',\n",
              "  '<r48',\n",
              "  '<r49',\n",
              "  '<r50',\n",
              "  '<r51',\n",
              "  '<r52',\n",
              "  '<r53',\n",
              "  '<r54',\n",
              "  '<r55',\n",
              "  '<r6',\n",
              "  '<r7',\n",
              "  '<r8',\n",
              "  '<r9',\n",
              "  '<u10',\n",
              "  '<u11',\n",
              "  '<u12',\n",
              "  '<u13',\n",
              "  '<u14',\n",
              "  '<u15',\n",
              "  '<u16',\n",
              "  '<u17',\n",
              "  '<u18',\n",
              "  '<u19',\n",
              "  '<u20',\n",
              "  '<u21',\n",
              "  '<u22',\n",
              "  '<u23',\n",
              "  '<u24',\n",
              "  '<u25',\n",
              "  '<u26',\n",
              "  '<u27',\n",
              "  '<u28',\n",
              "  '<u29',\n",
              "  '<u30',\n",
              "  '<u31',\n",
              "  '<u32',\n",
              "  '<u33',\n",
              "  '<u34',\n",
              "  '<u35',\n",
              "  '<u36',\n",
              "  '<u37',\n",
              "  '<u38',\n",
              "  '<u39',\n",
              "  '<u40',\n",
              "  '<u41',\n",
              "  '<u42',\n",
              "  '<u43',\n",
              "  '<u44',\n",
              "  '<u45',\n",
              "  '<u46',\n",
              "  '<u47',\n",
              "  '<u48',\n",
              "  '<u49',\n",
              "  '<u50',\n",
              "  '<u51',\n",
              "  '<u52',\n",
              "  '<u53',\n",
              "  '<u54',\n",
              "  '<u55',\n",
              "  '<u6',\n",
              "  '<u7',\n",
              "  '<u8',\n",
              "  '<u9'},\n",
              " ('00>',\n",
              "  '01>',\n",
              "  '02>',\n",
              "  '03>',\n",
              "  '04>',\n",
              "  '05>',\n",
              "  '06>',\n",
              "  '07>',\n",
              "  '08>',\n",
              "  '09>',\n",
              "  '0>',\n",
              "  '10>',\n",
              "  '11>',\n",
              "  '12>',\n",
              "  '13>',\n",
              "  '14>',\n",
              "  '15>',\n",
              "  '16>',\n",
              "  '17>',\n",
              "  '18>',\n",
              "  '19>',\n",
              "  '1>',\n",
              "  '20>',\n",
              "  '21>',\n",
              "  '22>',\n",
              "  '23>',\n",
              "  '24>',\n",
              "  '25>',\n",
              "  '26>',\n",
              "  '27>',\n",
              "  '28>',\n",
              "  '29>',\n",
              "  '2>',\n",
              "  '30>',\n",
              "  '31>',\n",
              "  '32>',\n",
              "  '33>',\n",
              "  '34>',\n",
              "  '35>',\n",
              "  '36>',\n",
              "  '37>',\n",
              "  '38>',\n",
              "  '39>',\n",
              "  '3>',\n",
              "  '40>',\n",
              "  '41>',\n",
              "  '42>',\n",
              "  '43>',\n",
              "  '44>',\n",
              "  '45>',\n",
              "  '46>',\n",
              "  '47>',\n",
              "  '48>',\n",
              "  '49>',\n",
              "  '4>',\n",
              "  '50>',\n",
              "  '51>',\n",
              "  '52>',\n",
              "  '53>',\n",
              "  '54>',\n",
              "  '55>',\n",
              "  '56>',\n",
              "  '57>',\n",
              "  '58>',\n",
              "  '59>',\n",
              "  '5>',\n",
              "  '60>',\n",
              "  '61>',\n",
              "  '62>',\n",
              "  '63>',\n",
              "  '64>',\n",
              "  '65>',\n",
              "  '66>',\n",
              "  '67>',\n",
              "  '68>',\n",
              "  '69>',\n",
              "  '6>',\n",
              "  '70>',\n",
              "  '71>',\n",
              "  '72>',\n",
              "  '73>',\n",
              "  '74>',\n",
              "  '75>',\n",
              "  '76>',\n",
              "  '77>',\n",
              "  '78>',\n",
              "  '79>',\n",
              "  '7>',\n",
              "  '80>',\n",
              "  '81>',\n",
              "  '82>',\n",
              "  '83>',\n",
              "  '84>',\n",
              "  '85>',\n",
              "  '86>',\n",
              "  '87>',\n",
              "  '88>',\n",
              "  '89>',\n",
              "  '8>',\n",
              "  '90>',\n",
              "  '91>',\n",
              "  '92>',\n",
              "  '93>',\n",
              "  '94>',\n",
              "  '95>',\n",
              "  '96>',\n",
              "  '97>',\n",
              "  '98>',\n",
              "  '99>',\n",
              "  '9>',\n",
              "  '>'): {'<r1', '<r2', '<r3', '<r4', '<u1', '<u2', '<u3', '<u4'},\n",
              " ('NULL', 'h'): {'a2mr',\n",
              "  'antz4amī',\n",
              "  'lak',\n",
              "  'mta2lq',\n",
              "  'mtas2r',\n",
              "  'qaim',\n",
              "  'sal',\n",
              "  'z3rurī'},\n",
              " ('a', 'ī'): {'achh', 'amrīk', 'hug'},\n",
              " ('NULL', 'aṉ'): {'karruaiī', 'nukrī', 'pabndī'},\n",
              " ('NULL', 'uṉ'): {'arb',\n",
              "  'brt2rfī',\n",
              "  'bīnk',\n",
              "  'dhaiī',\n",
              "  'hzar',\n",
              "  'khandan',\n",
              "  'kushsh',\n",
              "  'lakh',\n",
              "  'nrkh',\n",
              "  'saiīkl',\n",
              "  'sbzī',\n",
              "  'shhrī',\n",
              "  'srhd',\n",
              "  'tajr',\n",
              "  'tnkhuah',\n",
              "  'us3ulī',\n",
              "  'uzart'},\n",
              " ('NULL', 'uṉ', 'ī'): {'dar', 'hkumt', 'kar', 'karubar', 'khrīdar', 'tbdīl'},\n",
              " ('e', 'h', 'uṉ'): {'ma2ahd', 'mns3ub', 'sha2b'},\n",
              " ('e', 'ī'): {'agl', 'bṛht', 'hugi', 'hui', 'hun', 'phl'},\n",
              " ('NULL', 's'): {'akanṭ', 'granṭ', 'mask', 'planṭ', 'rpurṭ', 'īunṭ', 'ṭīk'},\n",
              " ('NULL', 'ī'): {'amdad',\n",
              "  'aīran',\n",
              "  'bazar',\n",
              "  'bhal',\n",
              "  'bhart',\n",
              "  'bhr',\n",
              "  'bhtr',\n",
              "  'bnd',\n",
              "  'bīrun',\n",
              "  'bīruzgar',\n",
              "  'chīn',\n",
              "  'frahm',\n",
              "  'ghlt2',\n",
              "  'japan',\n",
              "  'khrab',\n",
              "  'ma2t2l',\n",
              "  'mah',\n",
              "  'mal',\n",
              "  'mlk',\n",
              "  'mnsukh',\n",
              "  'mntql',\n",
              "  'mnz4ur',\n",
              "  'mqam',\n",
              "  'nrm',\n",
              "  'pakstan',\n",
              "  'qanun',\n",
              "  'skht',\n",
              "  'ta2īnat',\n",
              "  'tjart',\n",
              "  'tīar',\n",
              "  'tīz',\n",
              "  'uaps',\n",
              "  'ufaq',\n",
              "  'īqīn'},\n",
              " ('NULL', 'at'): {'amkan',\n",
              "  'aqts3adī',\n",
              "  'as2r',\n",
              "  'bramd',\n",
              "  'dramd',\n",
              "  'drmd',\n",
              "  'nqs3an',\n",
              "  'trsīl'},\n",
              " ('a', 'e'): {'apn', 'chhuṭ', 'krlī', 'krn', 'krrh', 'samn', 'skt', 'sun'},\n",
              " ('NULL', 'z'): {'fnḍ',\n",
              "  'fun',\n",
              "  'muṭr',\n",
              "  'sngl',\n",
              "  'sīkīurṭī',\n",
              "  'sīl',\n",
              "  'zun',\n",
              "  'ḍalr',\n",
              "  'ḍīuṭī',\n",
              "  'ṭīks'},\n",
              " ('e', 'h'): {'fīs3l',\n",
              "  'hual',\n",
              "  'jrman',\n",
              "  'khatm',\n",
              "  'khsar',\n",
              "  'kht2r',\n",
              "  'khzan',\n",
              "  'mt2alb',\n",
              "  'pīs'},\n",
              " ('NULL', 'iī'): {'aīshīa', 'mhnga', 'uba'},\n",
              " ('t', 'ī'): {'bhar', 'da2u', 'z3rur'},\n",
              " ('NULL', 'ne'): {'bna', 'bṛha', 'khul', 'lga', 'phncha', 'sam'},\n",
              " ('NULL', 'e'): {'drmīan', 'khan', 'kht2', 'mjh'},\n",
              " ('uṉ', 'ī'): {'s3na2t', 'saz', 'shhr'},\n",
              " ('NULL', 'rz'): {'fail', 'rīgulīṭ', 'sīnīṭ'},\n",
              " ('NULL', 'ṉ'): {'giī', 'lgī', 's3na2tī'},\n",
              " ('NULL', 'ng'): {'has', 'luḍ', 'rīṭ', 'shīḍul', 'urk'},\n",
              " ('NULL', 'l'): {'jng', 'sng', 'sīnṭr'},\n",
              " ('NULL', 't'): {'ma2aun', 'mkhalf', 'mlkī'},\n",
              " ('NULL', 'atī'): {'malī', 'ta2mīr', 'trqī'},\n",
              " ('NULL', 'ات'): {'اثر',\n",
              "  'اقتصادی',\n",
              "  'امکان',\n",
              "  'برامد',\n",
              "  'ترسیل',\n",
              "  'درامد',\n",
              "  'درمد',\n",
              "  'نقصان'},\n",
              " ('NULL', 'اں'): {'نوکری', 'پابندی', 'کارروائی'},\n",
              " ('NULL', 'وں'): {'ارب',\n",
              "  'برطرفی',\n",
              "  'بینک',\n",
              "  'تاجر',\n",
              "  'تنخواہ',\n",
              "  'خاندان',\n",
              "  'دہائی',\n",
              "  'سائیکل',\n",
              "  'سبزی',\n",
              "  'سرحد',\n",
              "  'شہری',\n",
              "  'لاکھ',\n",
              "  'نرخ',\n",
              "  'وزارت',\n",
              "  'وصولی',\n",
              "  'کوشش',\n",
              "  'ہزار'},\n",
              " ('NULL', 'وں', 'ی'): {'تبدیل', 'حکومت', 'خریدار', 'دار', 'کار', 'کاروبار'},\n",
              " ('وں', 'ہ', 'ے'): {'شعب', 'معاہد', 'منصوب'},\n",
              " ('NULL', 'ز'): {'زون',\n",
              "  'سنگل',\n",
              "  'سیل',\n",
              "  'سیکیورٹی',\n",
              "  'فنڈ',\n",
              "  'فون',\n",
              "  'موٹر',\n",
              "  'ٹیکس',\n",
              "  'ڈالر',\n",
              "  'ڈیوٹی',\n",
              "  'کیس'},\n",
              " ('ہ', 'ے'): {'جرمان',\n",
              "  'حوال',\n",
              "  'خاتم',\n",
              "  'خزان',\n",
              "  'خسار',\n",
              "  'خطر',\n",
              "  'فیصل',\n",
              "  'مطالب',\n",
              "  'پیس'},\n",
              " ('ی', 'ے'): {'اگل', 'بڑھت', 'پہل', 'ہوئ', 'ہون', 'ہوگئ'},\n",
              " ('NULL', 'ی'): {'امداد',\n",
              "  'ایران',\n",
              "  'بازار',\n",
              "  'بحال',\n",
              "  'بند',\n",
              "  'بھارت',\n",
              "  'بہتر',\n",
              "  'بیروزگار',\n",
              "  'بیرون',\n",
              "  'تجارت',\n",
              "  'تعینات',\n",
              "  'تیار',\n",
              "  'تیز',\n",
              "  'جاپان',\n",
              "  'خراب',\n",
              "  'سخت',\n",
              "  'غلط',\n",
              "  'فراہم',\n",
              "  'قانون',\n",
              "  'مال',\n",
              "  'ماہ',\n",
              "  'معطل',\n",
              "  'مقام',\n",
              "  'ملک',\n",
              "  'منتقل',\n",
              "  'منسوخ',\n",
              "  'منظور',\n",
              "  'نرم',\n",
              "  'واپس',\n",
              "  'وفاق',\n",
              "  'پاکستان',\n",
              "  'چین',\n",
              "  'یقین'},\n",
              " ('ا', 'ی'): {'امریک', 'اچھ', 'ہوگ'},\n",
              " ('NULL', 'ہ'): {'انتظامی', 'سال', 'ضروری', 'عمر', 'قائم', 'متاثر', 'متعلق'},\n",
              " ('ا', 'ے'): {'اپن', 'سامن', 'سون', 'سکت', 'چھوٹ', 'کررہ', 'کرلی', 'کرن'},\n",
              " ('NULL', 'س'): {'اکانٹ', 'رپورٹ', 'ماسک', 'ٹیک', 'پلانٹ', 'گرانٹ', 'یونٹ'},\n",
              " ('NULL', 'ئی'): {'ایشیا', 'مہنگا', 'وبا'},\n",
              " ('NULL', 'نے'): {'بنا', 'بڑھا', 'سام', 'لگا', 'پہنچا', 'کھول'},\n",
              " ('NULL', 'ے'): {'خان', 'درمیان', 'مجھ'},\n",
              " ('ت', 'ی'): {'بھار', 'دعو', 'ضرور'},\n",
              " ('وں', 'ی'): {'ساز', 'شہر', 'صنعت'},\n",
              " ('NULL', 'اتی'): {'ترقی', 'تعمیر', 'مالی'},\n",
              " ('NULL', 'ل'): {'جنگ', 'سنگ', 'سینٹر'},\n",
              " ('NULL', 'نگ'): {'ریٹ', 'شیڈول', 'لوڈ', 'ورک', 'ہاس'},\n",
              " ('NULL', 'رز'): {'ریگولیٹ', 'سینیٹ', 'فائل'},\n",
              " ('NULL', 'ں'): {'صنعتی', 'لگی', 'گئی'},\n",
              " ('NULL', 'ت'): {'مخالف', 'معاون', 'ملکی'}}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stem_sigs = lxa_ur.signatures_to_stems()\n"
      ],
      "metadata": {
        "id": "kx-IMa8dwWVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, itm in enumerate(stem_sigs):\n",
        "  if len (itm) >2 and len(itm) < 8 :\n",
        "    print(i, itm, stem_sigs[itm])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X56DUf5pww4s",
        "outputId": "44ec500e-0db4-49f0-f07e-0067c97a38e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6 ('NULL', 'uṉ', 'ī') {'karubar', 'hkumt', 'kar', 'dar', 'tbdīl', 'khrīdar'}\n",
            "7 ('e', 'h', 'uṉ') {'mns3ub', 'ma2ahd', 'sha2b'}\n",
            "29 ('NULL', 'وں', 'ی') {'حکومت', 'خریدار', 'کاروبار', 'دار', 'تبدیل', 'کار'}\n",
            "30 ('وں', 'ہ', 'ے') {'منصوب', 'معاہد', 'شعب'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0--JjMHxApOp"
      },
      "source": [
        "# Ployglot - using pre-trained morfessor models\n",
        "\n",
        "https://polyglot.readthedocs.io/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH6wf8ohA4rY"
      },
      "source": [
        "Installing the libraries required by polyglot\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_PqxdymCQEG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247bb712-5917-4fc7-99d1-e0523ffbafc3"
      },
      "source": [
        "!brew install icu4c\n",
        "!export ICU_VERSION=58\n",
        "!export PYICU_INCLUDES=/usr/local/Cellar/icu4c/58.2/include\n",
        "!export PYICU_LFLAGS=-L/usr/local/Cellar/icu4c/58.2/lib\n",
        "!pip install pyicu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: brew: command not found\n",
            "Requirement already satisfied: pyicu in /usr/local/lib/python3.10/dist-packages (2.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoRGt86TCQPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b216106-0999-4948-bd63-431c53b9ac30"
      },
      "source": [
        "!pip install pycld2\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycld2\n",
            "  Downloading pycld2-0.41.tar.gz (41.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp310-cp310-linux_x86_64.whl size=9904066 sha256=c22eaebb3c5050c15962c681ab31138fc86a0b73f5f5af882847c4bdce532687\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/81/31/240c89c845e008a93d98542325270007de595bfd356eb0b06c\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2XPGxiCCdjy"
      },
      "source": [
        "installing polyglot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kak6LGeoJXBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac6bd0b-86a9-49b3-c04c-f225512bda78"
      },
      "source": [
        "!pip install polyglot\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting polyglot\n",
            "  Downloading polyglot-16.7.4.tar.gz (126 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: polyglot\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52562 sha256=7100189ad7e9b9fd39c486cd7d48a280db614441fad573984d0bd141cd97f84c\n",
            "  Stored in directory: /root/.cache/pip/wheels/aa/92/4a/b172589446ba537db3bdb9a1f2204f27fe71217981c14ac368\n",
            "Successfully built polyglot\n",
            "Installing collected packages: polyglot\n",
            "Successfully installed polyglot-16.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOlcsg1kJXB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "454af654-c39f-49dd-c79c-c222a83c275f"
      },
      "source": [
        "!pip install morfessor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting morfessor\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: morfessor\n",
            "Successfully installed morfessor-2.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xLCQAbwJXB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1327d841-02bb-40cf-8966-2c93aab10b43"
      },
      "source": [
        "!polyglot download morph2.ur"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[polyglot_data] Downloading package morph2.ur to\n",
            "[polyglot_data]     /root/polyglot_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!polyglot download morph2.hi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBMMKKKTs_nE",
        "outputId": "31efe46d-e6fa-4fba-8af4-1fd5ad74b225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[polyglot_data] Downloading package morph2.hi to\n",
            "[polyglot_data]     /root/polyglot_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUnqy4eTDOo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db7341a0-df96-45d5-d427-478b512226c8"
      },
      "source": [
        "from polyglot.text import Text, Word\n",
        "\n",
        "processed = Text(\"لڑکیاں کتابیں لڑکوں ملکوں شہروں گرتا گرتے لکھواتی\",'ur')\n",
        "\n",
        "for w in processed.words:\n",
        "  print(w.morphemes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['لڑ', 'ک', 'یاں']\n",
            "['کتاب', 'یں']\n",
            "['لڑ', 'ک', 'وں']\n",
            "['ملک', 'وں']\n",
            "['شہر', 'وں']\n",
            "['گر', 'تا']\n",
            "['گر', 'تے']\n",
            "['لکھوا', 'تی']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "processed = Text(\"लड़कियां, किताबें , लड़कों , मूलकों , गिरता ,गीते ,गीति, लिखवाती \")\n",
        "\n",
        "for w in processed.words:\n",
        "  print(w.morphemes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epwHmTIstYk-",
        "outputId": "16cbb695-5f77-4c35-9c78-be1d83453c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['लड़क', 'ियां']\n",
            "[',']\n",
            "['किताब', 'ें']\n",
            "[',']\n",
            "['लड़क', 'ों']\n",
            "[',']\n",
            "['मूल', 'कों']\n",
            "[',']\n",
            "['गिर', 'ता']\n",
            "[',']\n",
            "['गी', 'ते']\n",
            "[',']\n",
            "['गी', 'ति']\n",
            "[',']\n",
            "['लिख', 'वात', 'ी']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53rtYfB7tmIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea76440-d4b6-4fbe-9096-810103f4ee7a"
      },
      "source": [
        "processed = Text(\"بعدازنمازمغرب کبوتراڑرہےتھے \",'ur')\n",
        "\n",
        "for w in processed.words:\n",
        "  print(w.morphemes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['بعد', 'از', 'نماز', 'م', 'غرب']\n",
            "['ک', 'بو', 'تر', 'اڑ', 'رہے', 'تھے']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h3TULKkxZN6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnjsZrw0ZQPh",
        "outputId": "7137b686-8586-4336-bf40-cad051349685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_hub<0.18,>=0.16.4 (from tokenizers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (3.12.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<0.18,>=0.16.4->tokenizers) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<0.18,>=0.16.4->tokenizers) (2023.7.22)\n",
            "Installing collected packages: huggingface_hub, tokenizers\n",
            "Successfully installed huggingface_hub-0.17.3 tokenizers-0.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install word-piece-tokenizer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL-w0RsOZ6GV",
        "outputId": "10bf7c0c-2487-4b89-da30-705372391b84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting word-piece-tokenizer\n",
            "  Downloading word_piece_tokenizer-1.0.1-py3-none-any.whl (119 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m112.6/119.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: word-piece-tokenizer\n",
            "Successfully installed word-piece-tokenizer-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from word_piece_tokenizer import WordPieceTokenizer\n",
        "tokenizer = WordPieceTokenizer()\n",
        "\n",
        "ids = tokenizer.tokenize('reading a storybooks!')\n",
        "# [101, 3752, 1037, 2466, 8654, 999, 102]\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids)\n",
        "# ['[CLS]', 'reading', 'a', 'story', '##book', '!', '[SEP]']\n",
        "\n",
        "\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8er4fsgZ6pc",
        "outputId": "7fbb650a-3f85-4e2e-e8f2-a32b198197ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS]', 'reading', 'a', 'story', '##books', '!', '[SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g0pOb1jCaS47"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}